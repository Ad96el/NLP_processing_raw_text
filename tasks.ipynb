{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitbasecondabd88c407e14c40be84e83b5bdd135b46",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Processing Raw Text\n",
    "\n",
    "The goal of this chapter is to answer to following questions: \n",
    "\n",
    "- How can we write programs to access texts?\n",
    "- How can we split documents up into individual words? \n",
    "- How can we write programs to produce formatted output and save those?\n",
    "\n",
    "This notebook provides some example and tasks which you have to do. \n",
    "\n",
    "With answering all questions you will own a pipline for processing raw text. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Some Basics in Python\n",
    "\n",
    "For process some raw text it is necessary to remind the fundamental data type strings and his functionalities."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"This is an example string!\"\n",
    "\n",
    "\"\"\"\n",
    "We can indexing the values of a string, by using [index].\n",
    "Remind: in python negative index values are also possible!\n",
    "\"\"\"\n",
    "\n",
    "print(example[0])\n",
    "print(example[1])\n",
    "\n",
    "\"\"\"\n",
    "The concatenation of two strings can be realised by \"+\".\n",
    "\"\"\"\n",
    "\n",
    "example2 = \"This is an other example of a string!\"\n",
    "print(example + example2)\n",
    "\n",
    "\"\"\"\n",
    "We can also access to substrings by using square brackets. \n",
    "The first value is determining the start of the substring. The Second value the end and the last value the step length: [start:end:step_lenght]\n",
    "\"\"\"\n",
    "\n",
    "print(example[:10])\n",
    "print(example[10:])\n",
    "print(example[::2])"
   ]
  },
  {
   "source": [
    "<h3 style =\"color: red\" > Tasks: <h3 />\n",
    "\n",
    "- Define a string s = 'The Godfther'. Write statement that changes this to \"The Godfather\". You can only use concatenation and slicing.  \n",
    "\n",
    "- What will happen if we will access on the 13rd element of the string s? Why? \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here: "
   ]
  },
  {
   "source": [
    "## Accessing Text\n",
    "\n",
    "The most important source of texts is undoubtedly the Web. The project <a href=\"https://www.gutenberg.org\">Guttenberg</a> is collection of over 25.000 free online books. Unfortunaly, the Guttenberg project is from german IP addresses currently unavailable. \n",
    "For present of process raw text we will access on the text of <a href=\"https://en.wikipedia.org/wiki/The_Godfather\">this link</a>.\n",
    "\n",
    "The code block below is demonstrating how you can access text from any website:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "url = \"https://en.wikipedia.org/wiki/The_Godfather\"\n",
    "raw = urlopen(url).read().decode(\"utf-8\")\n",
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print( raw[:100])"
   ]
  },
  {
   "source": [
    "By access text from the Web, we will always receive all meta tags from the HTML protocol.\n",
    "\n",
    "<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Beautiful Soup</a>  is a providing helper function for pulling the text out of the tags."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "text = BeautifulSoup(raw , \"html.parser\").get_text()[100:]\n",
    "print(text[:100])"
   ]
  },
  {
   "source": [
    "Be Aware: even with BeautifulSoup the text contains unwanted material.\n",
    "We are not intereseted in such as whitespace, line breaks or blank lines. \n",
    "\n",
    "Our goal is it to break up the string into words and punction. This step is called <b>tokenization</b>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "tokens = nltk.word_tokenize(text)[20:]\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[100:10])\n",
    "nltk_text = nltk.Text(tokens)\n",
    "print(type(nltk_text))\n",
    "print(nltk_text)"
   ]
  },
  {
   "source": [
    "Now we can normalize the text. We will also discuss a even more \"aggressiv\" normalization step of a text below. \n",
    "\n",
    "For the normalization, we will transform all words to lower case. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w.lower() for w in tokens]\n",
    "vocab = sorted(set(words))\n",
    "print(vocab[:10])"
   ]
  },
  {
   "source": [
    "The Figure below is summarizing what we have covered yet.\n",
    "\n",
    "<img src=\"https://www.nltk.org/images/pipeline1.png\" width=\"90%\" height=\"400\"/>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3 style =\"color: red\" > Tasks: <h3 />\n",
    "\n",
    "- Write a code to get the the current teperature of Berlin. Save the value as temp. We will need it later. (Hint: use this Link: https://www.timeanddate.com/weather/germany/berlin. The important area should be between 1890 - 1950)\n",
    "\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# your code here\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.timeanddate.com/weather/germany/berlin\"\n",
    "raw = urlopen(url).read().decode(\"utf-8\")\n",
    "text = BeautifulSoup(raw , \"html.parser\").get_text()[100:]\n",
    "str(text[1890:1950])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' (Averages)Now4\\xa0°CPassing clouds.Feels Like: 1\\xa0°CForecast: 2'"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Unicode'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-651107668237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mUnicode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1890\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1950\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Unicode'"
     ]
    }
   ],
   "source": [
    "import Unicode \n",
    "word = Unicode.unicode(str(text[1890:1950]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}